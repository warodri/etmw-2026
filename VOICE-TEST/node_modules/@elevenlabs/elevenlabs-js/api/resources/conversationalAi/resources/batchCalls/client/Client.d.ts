import type { BaseClientOptions, BaseRequestOptions } from "@elevenlabs/elevenlabs-js/BaseClient";
import { type NormalizedClientOptions } from "@elevenlabs/elevenlabs-js/BaseClient";
import * as core from "@elevenlabs/elevenlabs-js/core";
import * as ElevenLabs from "@elevenlabs/elevenlabs-js/api";
export declare namespace BatchCallsClient {
    type Options = BaseClientOptions;
    interface RequestOptions extends BaseRequestOptions {
    }
}
export declare class BatchCallsClient {
    protected readonly _options: NormalizedClientOptions<BatchCallsClient.Options>;
    constructor(options?: BatchCallsClient.Options);
    /**
     * Submit a batch call request to schedule calls for multiple recipients.
     *
     * @param {ElevenLabs.conversationalAi.BodySubmitABatchCallRequestV1ConvaiBatchCallingSubmitPost} request
     * @param {BatchCallsClient.RequestOptions} requestOptions - Request-specific configuration.
     *
     * @throws {@link ElevenLabs.UnprocessableEntityError}
     *
     * @example
     *     await client.conversationalAi.batchCalls.create({
     *         callName: "call_name",
     *         agentId: "agent_id",
     *         recipients: [{}]
     *     })
     */
    create(request: ElevenLabs.conversationalAi.BodySubmitABatchCallRequestV1ConvaiBatchCallingSubmitPost, requestOptions?: BatchCallsClient.RequestOptions): core.HttpResponsePromise<ElevenLabs.BatchCallResponse>;
    private __create;
    /**
     * Get all batch calls for the current workspace.
     *
     * @param {ElevenLabs.conversationalAi.BatchCallsListRequest} request
     * @param {BatchCallsClient.RequestOptions} requestOptions - Request-specific configuration.
     *
     * @throws {@link ElevenLabs.UnprocessableEntityError}
     *
     * @example
     *     await client.conversationalAi.batchCalls.list({
     *         limit: 1,
     *         lastDoc: "last_doc"
     *     })
     */
    list(request?: ElevenLabs.conversationalAi.BatchCallsListRequest, requestOptions?: BatchCallsClient.RequestOptions): core.HttpResponsePromise<ElevenLabs.WorkspaceBatchCallsResponse>;
    private __list;
    /**
     * Get detailed information about a batch call including all recipients.
     *
     * @param {string} batch_id
     * @param {BatchCallsClient.RequestOptions} requestOptions - Request-specific configuration.
     *
     * @throws {@link ElevenLabs.UnprocessableEntityError}
     *
     * @example
     *     await client.conversationalAi.batchCalls.get("batch_id")
     */
    get(batch_id: string, requestOptions?: BatchCallsClient.RequestOptions): core.HttpResponsePromise<ElevenLabs.BatchCallDetailedResponse>;
    private __get;
    /**
     * Permanently delete a batch call and all recipient records. Conversations remain in history.
     *
     * @param {string} batch_id
     * @param {BatchCallsClient.RequestOptions} requestOptions - Request-specific configuration.
     *
     * @throws {@link ElevenLabs.UnprocessableEntityError}
     *
     * @example
     *     await client.conversationalAi.batchCalls.delete("batch_id")
     */
    delete(batch_id: string, requestOptions?: BatchCallsClient.RequestOptions): core.HttpResponsePromise<void>;
    private __delete;
    /**
     * Cancel a running batch call and set all recipients to cancelled status.
     *
     * @param {string} batch_id
     * @param {BatchCallsClient.RequestOptions} requestOptions - Request-specific configuration.
     *
     * @throws {@link ElevenLabs.UnprocessableEntityError}
     *
     * @example
     *     await client.conversationalAi.batchCalls.cancel("batch_id")
     */
    cancel(batch_id: string, requestOptions?: BatchCallsClient.RequestOptions): core.HttpResponsePromise<ElevenLabs.BatchCallResponse>;
    private __cancel;
    /**
     * Retry a batch call, calling failed and no-response recipients again.
     *
     * @param {string} batch_id
     * @param {BatchCallsClient.RequestOptions} requestOptions - Request-specific configuration.
     *
     * @throws {@link ElevenLabs.UnprocessableEntityError}
     *
     * @example
     *     await client.conversationalAi.batchCalls.retry("batch_id")
     */
    retry(batch_id: string, requestOptions?: BatchCallsClient.RequestOptions): core.HttpResponsePromise<ElevenLabs.BatchCallResponse>;
    private __retry;
}
