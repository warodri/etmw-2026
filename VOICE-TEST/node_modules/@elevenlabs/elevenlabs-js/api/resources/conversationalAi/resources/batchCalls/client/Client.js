"use strict";
// This file was auto-generated by Fern from our API Definition.
var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar = (this && this.__importStar) || (function () {
    var ownKeys = function(o) {
        ownKeys = Object.getOwnPropertyNames || function (o) {
            var ar = [];
            for (var k in o) if (Object.prototype.hasOwnProperty.call(o, k)) ar[ar.length] = k;
            return ar;
        };
        return ownKeys(o);
    };
    return function (mod) {
        if (mod && mod.__esModule) return mod;
        var result = {};
        if (mod != null) for (var k = ownKeys(mod), i = 0; i < k.length; i++) if (k[i] !== "default") __createBinding(result, mod, k[i]);
        __setModuleDefault(result, mod);
        return result;
    };
})();
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.BatchCallsClient = void 0;
const BaseClient_1 = require("../../../../../../BaseClient");
const core = __importStar(require("../../../../../../core"));
const headers_1 = require("../../../../../../core/headers");
const environments = __importStar(require("../../../../../../environments"));
const handleNonStatusCodeError_1 = require("../../../../../../errors/handleNonStatusCodeError");
const errors = __importStar(require("../../../../../../errors/index"));
const serializers = __importStar(require("../../../../../../serialization/index"));
const ElevenLabs = __importStar(require("../../../../../index"));
class BatchCallsClient {
    constructor(options = {}) {
        this._options = (0, BaseClient_1.normalizeClientOptions)(options);
    }
    /**
     * Submit a batch call request to schedule calls for multiple recipients.
     *
     * @param {ElevenLabs.conversationalAi.BodySubmitABatchCallRequestV1ConvaiBatchCallingSubmitPost} request
     * @param {BatchCallsClient.RequestOptions} requestOptions - Request-specific configuration.
     *
     * @throws {@link ElevenLabs.UnprocessableEntityError}
     *
     * @example
     *     await client.conversationalAi.batchCalls.create({
     *         callName: "call_name",
     *         agentId: "agent_id",
     *         recipients: [{}]
     *     })
     */
    create(request, requestOptions) {
        return core.HttpResponsePromise.fromPromise(this.__create(request, requestOptions));
    }
    __create(request, requestOptions) {
        return __awaiter(this, void 0, void 0, function* () {
            var _a, _b, _c, _d, _e, _f, _g, _h, _j, _k, _l, _m;
            const _headers = (0, headers_1.mergeHeaders)((_a = this._options) === null || _a === void 0 ? void 0 : _a.headers, (0, headers_1.mergeOnlyDefinedHeaders)({ "xi-api-key": (_b = requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.apiKey) !== null && _b !== void 0 ? _b : (_c = this._options) === null || _c === void 0 ? void 0 : _c.apiKey }), requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.headers);
            const _response = yield ((_d = this._options.fetcher) !== null && _d !== void 0 ? _d : core.fetcher)({
                url: core.url.join((_f = (_e = (yield core.Supplier.get(this._options.baseUrl))) !== null && _e !== void 0 ? _e : (yield core.Supplier.get(this._options.environment))) !== null && _f !== void 0 ? _f : environments.ElevenLabsEnvironment.Production, "v1/convai/batch-calling/submit"),
                method: "POST",
                headers: _headers,
                contentType: "application/json",
                queryParameters: requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.queryParams,
                requestType: "json",
                body: serializers.conversationalAi.BodySubmitABatchCallRequestV1ConvaiBatchCallingSubmitPost.jsonOrThrow(request, { unrecognizedObjectKeys: "strip" }),
                timeoutMs: ((_j = (_g = requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.timeoutInSeconds) !== null && _g !== void 0 ? _g : (_h = this._options) === null || _h === void 0 ? void 0 : _h.timeoutInSeconds) !== null && _j !== void 0 ? _j : 240) * 1000,
                maxRetries: (_k = requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.maxRetries) !== null && _k !== void 0 ? _k : (_l = this._options) === null || _l === void 0 ? void 0 : _l.maxRetries,
                abortSignal: requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.abortSignal,
                fetchFn: (_m = this._options) === null || _m === void 0 ? void 0 : _m.fetch,
                logging: this._options.logging,
            });
            if (_response.ok) {
                return {
                    data: serializers.BatchCallResponse.parseOrThrow(_response.body, {
                        unrecognizedObjectKeys: "passthrough",
                        allowUnrecognizedUnionMembers: true,
                        allowUnrecognizedEnumValues: true,
                        breadcrumbsPrefix: ["response"],
                    }),
                    rawResponse: _response.rawResponse,
                };
            }
            if (_response.error.reason === "status-code") {
                switch (_response.error.statusCode) {
                    case 422:
                        throw new ElevenLabs.UnprocessableEntityError(serializers.HttpValidationError.parseOrThrow(_response.error.body, {
                            unrecognizedObjectKeys: "passthrough",
                            allowUnrecognizedUnionMembers: true,
                            allowUnrecognizedEnumValues: true,
                            breadcrumbsPrefix: ["response"],
                        }), _response.rawResponse);
                    default:
                        throw new errors.ElevenLabsError({
                            statusCode: _response.error.statusCode,
                            body: _response.error.body,
                            rawResponse: _response.rawResponse,
                        });
                }
            }
            return (0, handleNonStatusCodeError_1.handleNonStatusCodeError)(_response.error, _response.rawResponse, "POST", "/v1/convai/batch-calling/submit");
        });
    }
    /**
     * Get all batch calls for the current workspace.
     *
     * @param {ElevenLabs.conversationalAi.BatchCallsListRequest} request
     * @param {BatchCallsClient.RequestOptions} requestOptions - Request-specific configuration.
     *
     * @throws {@link ElevenLabs.UnprocessableEntityError}
     *
     * @example
     *     await client.conversationalAi.batchCalls.list({
     *         limit: 1,
     *         lastDoc: "last_doc"
     *     })
     */
    list(request = {}, requestOptions) {
        return core.HttpResponsePromise.fromPromise(this.__list(request, requestOptions));
    }
    __list() {
        return __awaiter(this, arguments, void 0, function* (request = {}, requestOptions) {
            var _a, _b, _c, _d, _e, _f, _g, _h, _j, _k, _l, _m;
            const { limit, lastDoc } = request;
            const _queryParams = {};
            if (limit != null) {
                _queryParams.limit = limit.toString();
            }
            if (lastDoc != null) {
                _queryParams.last_doc = lastDoc;
            }
            const _headers = (0, headers_1.mergeHeaders)((_a = this._options) === null || _a === void 0 ? void 0 : _a.headers, (0, headers_1.mergeOnlyDefinedHeaders)({ "xi-api-key": (_b = requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.apiKey) !== null && _b !== void 0 ? _b : (_c = this._options) === null || _c === void 0 ? void 0 : _c.apiKey }), requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.headers);
            const _response = yield ((_d = this._options.fetcher) !== null && _d !== void 0 ? _d : core.fetcher)({
                url: core.url.join((_f = (_e = (yield core.Supplier.get(this._options.baseUrl))) !== null && _e !== void 0 ? _e : (yield core.Supplier.get(this._options.environment))) !== null && _f !== void 0 ? _f : environments.ElevenLabsEnvironment.Production, "v1/convai/batch-calling/workspace"),
                method: "GET",
                headers: _headers,
                queryParameters: Object.assign(Object.assign({}, _queryParams), requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.queryParams),
                timeoutMs: ((_j = (_g = requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.timeoutInSeconds) !== null && _g !== void 0 ? _g : (_h = this._options) === null || _h === void 0 ? void 0 : _h.timeoutInSeconds) !== null && _j !== void 0 ? _j : 240) * 1000,
                maxRetries: (_k = requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.maxRetries) !== null && _k !== void 0 ? _k : (_l = this._options) === null || _l === void 0 ? void 0 : _l.maxRetries,
                abortSignal: requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.abortSignal,
                fetchFn: (_m = this._options) === null || _m === void 0 ? void 0 : _m.fetch,
                logging: this._options.logging,
            });
            if (_response.ok) {
                return {
                    data: serializers.WorkspaceBatchCallsResponse.parseOrThrow(_response.body, {
                        unrecognizedObjectKeys: "passthrough",
                        allowUnrecognizedUnionMembers: true,
                        allowUnrecognizedEnumValues: true,
                        breadcrumbsPrefix: ["response"],
                    }),
                    rawResponse: _response.rawResponse,
                };
            }
            if (_response.error.reason === "status-code") {
                switch (_response.error.statusCode) {
                    case 422:
                        throw new ElevenLabs.UnprocessableEntityError(serializers.HttpValidationError.parseOrThrow(_response.error.body, {
                            unrecognizedObjectKeys: "passthrough",
                            allowUnrecognizedUnionMembers: true,
                            allowUnrecognizedEnumValues: true,
                            breadcrumbsPrefix: ["response"],
                        }), _response.rawResponse);
                    default:
                        throw new errors.ElevenLabsError({
                            statusCode: _response.error.statusCode,
                            body: _response.error.body,
                            rawResponse: _response.rawResponse,
                        });
                }
            }
            return (0, handleNonStatusCodeError_1.handleNonStatusCodeError)(_response.error, _response.rawResponse, "GET", "/v1/convai/batch-calling/workspace");
        });
    }
    /**
     * Get detailed information about a batch call including all recipients.
     *
     * @param {string} batch_id
     * @param {BatchCallsClient.RequestOptions} requestOptions - Request-specific configuration.
     *
     * @throws {@link ElevenLabs.UnprocessableEntityError}
     *
     * @example
     *     await client.conversationalAi.batchCalls.get("batch_id")
     */
    get(batch_id, requestOptions) {
        return core.HttpResponsePromise.fromPromise(this.__get(batch_id, requestOptions));
    }
    __get(batch_id, requestOptions) {
        return __awaiter(this, void 0, void 0, function* () {
            var _a, _b, _c, _d, _e, _f, _g, _h, _j, _k, _l, _m;
            const _headers = (0, headers_1.mergeHeaders)((_a = this._options) === null || _a === void 0 ? void 0 : _a.headers, (0, headers_1.mergeOnlyDefinedHeaders)({ "xi-api-key": (_b = requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.apiKey) !== null && _b !== void 0 ? _b : (_c = this._options) === null || _c === void 0 ? void 0 : _c.apiKey }), requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.headers);
            const _response = yield ((_d = this._options.fetcher) !== null && _d !== void 0 ? _d : core.fetcher)({
                url: core.url.join((_f = (_e = (yield core.Supplier.get(this._options.baseUrl))) !== null && _e !== void 0 ? _e : (yield core.Supplier.get(this._options.environment))) !== null && _f !== void 0 ? _f : environments.ElevenLabsEnvironment.Production, `v1/convai/batch-calling/${core.url.encodePathParam(batch_id)}`),
                method: "GET",
                headers: _headers,
                queryParameters: requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.queryParams,
                timeoutMs: ((_j = (_g = requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.timeoutInSeconds) !== null && _g !== void 0 ? _g : (_h = this._options) === null || _h === void 0 ? void 0 : _h.timeoutInSeconds) !== null && _j !== void 0 ? _j : 240) * 1000,
                maxRetries: (_k = requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.maxRetries) !== null && _k !== void 0 ? _k : (_l = this._options) === null || _l === void 0 ? void 0 : _l.maxRetries,
                abortSignal: requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.abortSignal,
                fetchFn: (_m = this._options) === null || _m === void 0 ? void 0 : _m.fetch,
                logging: this._options.logging,
            });
            if (_response.ok) {
                return {
                    data: serializers.BatchCallDetailedResponse.parseOrThrow(_response.body, {
                        unrecognizedObjectKeys: "passthrough",
                        allowUnrecognizedUnionMembers: true,
                        allowUnrecognizedEnumValues: true,
                        breadcrumbsPrefix: ["response"],
                    }),
                    rawResponse: _response.rawResponse,
                };
            }
            if (_response.error.reason === "status-code") {
                switch (_response.error.statusCode) {
                    case 422:
                        throw new ElevenLabs.UnprocessableEntityError(serializers.HttpValidationError.parseOrThrow(_response.error.body, {
                            unrecognizedObjectKeys: "passthrough",
                            allowUnrecognizedUnionMembers: true,
                            allowUnrecognizedEnumValues: true,
                            breadcrumbsPrefix: ["response"],
                        }), _response.rawResponse);
                    default:
                        throw new errors.ElevenLabsError({
                            statusCode: _response.error.statusCode,
                            body: _response.error.body,
                            rawResponse: _response.rawResponse,
                        });
                }
            }
            return (0, handleNonStatusCodeError_1.handleNonStatusCodeError)(_response.error, _response.rawResponse, "GET", "/v1/convai/batch-calling/{batch_id}");
        });
    }
    /**
     * Permanently delete a batch call and all recipient records. Conversations remain in history.
     *
     * @param {string} batch_id
     * @param {BatchCallsClient.RequestOptions} requestOptions - Request-specific configuration.
     *
     * @throws {@link ElevenLabs.UnprocessableEntityError}
     *
     * @example
     *     await client.conversationalAi.batchCalls.delete("batch_id")
     */
    delete(batch_id, requestOptions) {
        return core.HttpResponsePromise.fromPromise(this.__delete(batch_id, requestOptions));
    }
    __delete(batch_id, requestOptions) {
        return __awaiter(this, void 0, void 0, function* () {
            var _a, _b, _c, _d, _e, _f, _g, _h, _j, _k, _l, _m;
            const _headers = (0, headers_1.mergeHeaders)((_a = this._options) === null || _a === void 0 ? void 0 : _a.headers, (0, headers_1.mergeOnlyDefinedHeaders)({ "xi-api-key": (_b = requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.apiKey) !== null && _b !== void 0 ? _b : (_c = this._options) === null || _c === void 0 ? void 0 : _c.apiKey }), requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.headers);
            const _response = yield ((_d = this._options.fetcher) !== null && _d !== void 0 ? _d : core.fetcher)({
                url: core.url.join((_f = (_e = (yield core.Supplier.get(this._options.baseUrl))) !== null && _e !== void 0 ? _e : (yield core.Supplier.get(this._options.environment))) !== null && _f !== void 0 ? _f : environments.ElevenLabsEnvironment.Production, `v1/convai/batch-calling/${core.url.encodePathParam(batch_id)}`),
                method: "DELETE",
                headers: _headers,
                queryParameters: requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.queryParams,
                timeoutMs: ((_j = (_g = requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.timeoutInSeconds) !== null && _g !== void 0 ? _g : (_h = this._options) === null || _h === void 0 ? void 0 : _h.timeoutInSeconds) !== null && _j !== void 0 ? _j : 240) * 1000,
                maxRetries: (_k = requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.maxRetries) !== null && _k !== void 0 ? _k : (_l = this._options) === null || _l === void 0 ? void 0 : _l.maxRetries,
                abortSignal: requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.abortSignal,
                fetchFn: (_m = this._options) === null || _m === void 0 ? void 0 : _m.fetch,
                logging: this._options.logging,
            });
            if (_response.ok) {
                return { data: undefined, rawResponse: _response.rawResponse };
            }
            if (_response.error.reason === "status-code") {
                switch (_response.error.statusCode) {
                    case 422:
                        throw new ElevenLabs.UnprocessableEntityError(serializers.HttpValidationError.parseOrThrow(_response.error.body, {
                            unrecognizedObjectKeys: "passthrough",
                            allowUnrecognizedUnionMembers: true,
                            allowUnrecognizedEnumValues: true,
                            breadcrumbsPrefix: ["response"],
                        }), _response.rawResponse);
                    default:
                        throw new errors.ElevenLabsError({
                            statusCode: _response.error.statusCode,
                            body: _response.error.body,
                            rawResponse: _response.rawResponse,
                        });
                }
            }
            return (0, handleNonStatusCodeError_1.handleNonStatusCodeError)(_response.error, _response.rawResponse, "DELETE", "/v1/convai/batch-calling/{batch_id}");
        });
    }
    /**
     * Cancel a running batch call and set all recipients to cancelled status.
     *
     * @param {string} batch_id
     * @param {BatchCallsClient.RequestOptions} requestOptions - Request-specific configuration.
     *
     * @throws {@link ElevenLabs.UnprocessableEntityError}
     *
     * @example
     *     await client.conversationalAi.batchCalls.cancel("batch_id")
     */
    cancel(batch_id, requestOptions) {
        return core.HttpResponsePromise.fromPromise(this.__cancel(batch_id, requestOptions));
    }
    __cancel(batch_id, requestOptions) {
        return __awaiter(this, void 0, void 0, function* () {
            var _a, _b, _c, _d, _e, _f, _g, _h, _j, _k, _l, _m;
            const _headers = (0, headers_1.mergeHeaders)((_a = this._options) === null || _a === void 0 ? void 0 : _a.headers, (0, headers_1.mergeOnlyDefinedHeaders)({ "xi-api-key": (_b = requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.apiKey) !== null && _b !== void 0 ? _b : (_c = this._options) === null || _c === void 0 ? void 0 : _c.apiKey }), requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.headers);
            const _response = yield ((_d = this._options.fetcher) !== null && _d !== void 0 ? _d : core.fetcher)({
                url: core.url.join((_f = (_e = (yield core.Supplier.get(this._options.baseUrl))) !== null && _e !== void 0 ? _e : (yield core.Supplier.get(this._options.environment))) !== null && _f !== void 0 ? _f : environments.ElevenLabsEnvironment.Production, `v1/convai/batch-calling/${core.url.encodePathParam(batch_id)}/cancel`),
                method: "POST",
                headers: _headers,
                queryParameters: requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.queryParams,
                timeoutMs: ((_j = (_g = requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.timeoutInSeconds) !== null && _g !== void 0 ? _g : (_h = this._options) === null || _h === void 0 ? void 0 : _h.timeoutInSeconds) !== null && _j !== void 0 ? _j : 240) * 1000,
                maxRetries: (_k = requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.maxRetries) !== null && _k !== void 0 ? _k : (_l = this._options) === null || _l === void 0 ? void 0 : _l.maxRetries,
                abortSignal: requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.abortSignal,
                fetchFn: (_m = this._options) === null || _m === void 0 ? void 0 : _m.fetch,
                logging: this._options.logging,
            });
            if (_response.ok) {
                return {
                    data: serializers.BatchCallResponse.parseOrThrow(_response.body, {
                        unrecognizedObjectKeys: "passthrough",
                        allowUnrecognizedUnionMembers: true,
                        allowUnrecognizedEnumValues: true,
                        breadcrumbsPrefix: ["response"],
                    }),
                    rawResponse: _response.rawResponse,
                };
            }
            if (_response.error.reason === "status-code") {
                switch (_response.error.statusCode) {
                    case 422:
                        throw new ElevenLabs.UnprocessableEntityError(serializers.HttpValidationError.parseOrThrow(_response.error.body, {
                            unrecognizedObjectKeys: "passthrough",
                            allowUnrecognizedUnionMembers: true,
                            allowUnrecognizedEnumValues: true,
                            breadcrumbsPrefix: ["response"],
                        }), _response.rawResponse);
                    default:
                        throw new errors.ElevenLabsError({
                            statusCode: _response.error.statusCode,
                            body: _response.error.body,
                            rawResponse: _response.rawResponse,
                        });
                }
            }
            return (0, handleNonStatusCodeError_1.handleNonStatusCodeError)(_response.error, _response.rawResponse, "POST", "/v1/convai/batch-calling/{batch_id}/cancel");
        });
    }
    /**
     * Retry a batch call, calling failed and no-response recipients again.
     *
     * @param {string} batch_id
     * @param {BatchCallsClient.RequestOptions} requestOptions - Request-specific configuration.
     *
     * @throws {@link ElevenLabs.UnprocessableEntityError}
     *
     * @example
     *     await client.conversationalAi.batchCalls.retry("batch_id")
     */
    retry(batch_id, requestOptions) {
        return core.HttpResponsePromise.fromPromise(this.__retry(batch_id, requestOptions));
    }
    __retry(batch_id, requestOptions) {
        return __awaiter(this, void 0, void 0, function* () {
            var _a, _b, _c, _d, _e, _f, _g, _h, _j, _k, _l, _m;
            const _headers = (0, headers_1.mergeHeaders)((_a = this._options) === null || _a === void 0 ? void 0 : _a.headers, (0, headers_1.mergeOnlyDefinedHeaders)({ "xi-api-key": (_b = requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.apiKey) !== null && _b !== void 0 ? _b : (_c = this._options) === null || _c === void 0 ? void 0 : _c.apiKey }), requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.headers);
            const _response = yield ((_d = this._options.fetcher) !== null && _d !== void 0 ? _d : core.fetcher)({
                url: core.url.join((_f = (_e = (yield core.Supplier.get(this._options.baseUrl))) !== null && _e !== void 0 ? _e : (yield core.Supplier.get(this._options.environment))) !== null && _f !== void 0 ? _f : environments.ElevenLabsEnvironment.Production, `v1/convai/batch-calling/${core.url.encodePathParam(batch_id)}/retry`),
                method: "POST",
                headers: _headers,
                queryParameters: requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.queryParams,
                timeoutMs: ((_j = (_g = requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.timeoutInSeconds) !== null && _g !== void 0 ? _g : (_h = this._options) === null || _h === void 0 ? void 0 : _h.timeoutInSeconds) !== null && _j !== void 0 ? _j : 240) * 1000,
                maxRetries: (_k = requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.maxRetries) !== null && _k !== void 0 ? _k : (_l = this._options) === null || _l === void 0 ? void 0 : _l.maxRetries,
                abortSignal: requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.abortSignal,
                fetchFn: (_m = this._options) === null || _m === void 0 ? void 0 : _m.fetch,
                logging: this._options.logging,
            });
            if (_response.ok) {
                return {
                    data: serializers.BatchCallResponse.parseOrThrow(_response.body, {
                        unrecognizedObjectKeys: "passthrough",
                        allowUnrecognizedUnionMembers: true,
                        allowUnrecognizedEnumValues: true,
                        breadcrumbsPrefix: ["response"],
                    }),
                    rawResponse: _response.rawResponse,
                };
            }
            if (_response.error.reason === "status-code") {
                switch (_response.error.statusCode) {
                    case 422:
                        throw new ElevenLabs.UnprocessableEntityError(serializers.HttpValidationError.parseOrThrow(_response.error.body, {
                            unrecognizedObjectKeys: "passthrough",
                            allowUnrecognizedUnionMembers: true,
                            allowUnrecognizedEnumValues: true,
                            breadcrumbsPrefix: ["response"],
                        }), _response.rawResponse);
                    default:
                        throw new errors.ElevenLabsError({
                            statusCode: _response.error.statusCode,
                            body: _response.error.body,
                            rawResponse: _response.rawResponse,
                        });
                }
            }
            return (0, handleNonStatusCodeError_1.handleNonStatusCodeError)(_response.error, _response.rawResponse, "POST", "/v1/convai/batch-calling/{batch_id}/retry");
        });
    }
}
exports.BatchCallsClient = BatchCallsClient;
